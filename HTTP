HTTP 笔记:
    IP 协议依赖与 MAC地址:
        1. 当数据在中转时，会利用下一站中转设备的MAC地址搜索下一个目标地址，此时就用到了arp协议。
        ARP协议是一种解析地址的协议，根据通信方的IP地址
    HTTP 协议的职责:
        1. 请求: 生成针对目标服务器的请求报文.
        2. 响应: 对web 服务器的请求内容进行处理。
    TCP 协议职责:
        1. 请求: 将HTTP请求报文分割成报文段，按序列号分为多个报文段，把每个报文段传输给对方。
        2. 响应: 从对方那里接受报文段，按序列号重组报文段。
    IP 协议职责:
        1. 搜索对方地址，一边中转，一边传输。



HTTP 权威指南:

    1. Http URI 与 资源:
        1). 协议, 2) 主机与端口号 3) 路径 4) 用户名/密码 5) 参数
        6)
    2. Http 报文:
        1. 报文流是如何流动的?
            从发送方流向接受方。
        2. HTTP 报文的组成部分?
            1) 请求方法 2) 请求资源 3) 协议版本 4) 首部 5) 状态码 6) 原因 7) 实体。
        3. 请求和响应报文的区别?

        4. 状态码?

        5. HTTP 首部是用来做什么的?

    3. Http 连接管理:
        1. HTTP 是如何使用 TCP 连接的？

        2. TCP 连接时延， 瓶颈以及存在的问题?

        3. http 优化-持久连接，管道连接?

        4. 管理连接时应该以及不应该做的事?

        5. TCP 首部 及 IP 首部:
            IP首部: 源及目的IP地址，长度 和其他标记。
            TCP首部: 端口号，TCP控制标示， 以及用于数据完整性和排序的一些数值。
        6. TCP 性能:
            1. HTTP 事务延迟:
                处理事务的试验相对较短，除非服务器的资源出现负载。
            2. TCP 时延:
                1) TCP建立握手时延:
                    http 在任意发送数据之前，会先建立连接。在握手连接的建立中，建立TCP连接花费的时间占大部分。

                2) TCP 慢启动拥塞控制:
                    TCP 的传输性能还取决于TCP 连接的使用期。
                    TCP 连接会随着数据传输进行自我调整，起初会限制连接的传输速度，如果传输成功会随着时间的推移提高传输速度。
                    这就是TCP 慢启动，用于防止互联网的过载与阻塞。
                    TCP 慢启动限制了 TCP 端点任意时刻发送的分组数。每成功发送一个分组就会获得两个分组的发送权限。等到两个分组被确认后
                    就能发送四个分组，以此类推。
                3) 数据聚集 nagle算法:
                    为了防止发送大量的小分组导致互联网阻塞， nagle算法鼓励用全尺寸来发送分组(LAN 是1500字节，因特网几百字节)，提高网络利用率。
                    只有当其他分组被确认后，nagle算法才允许发送非全尺寸分组。当分组未备确认，其他数据会先被缓存起来，或者缓存积累达到全尺寸数据时，
                    才会发送缓存数据。
                    性能问题:
                        1. 小的分组会因永远不会到来的数据产生时延。
                        2. 在确认分组确认前，nagle算法会阻止分组发送，而分组确认会被延时确认算法阻塞100～200ms
                4) 捎带确认的 TCP延时确认算法:
                    因特网无法保证可靠的分组传输，在因特网路由繁忙时会肆意丢弃分组。
                    TCP 有自己的可靠确认机制，每个TCP 段都有序列号和数据完整性校验和。当接受者受到后会向发送者发送确认分组，如果
                    发送者在规定的时间内没有受到确认分组，则认定分组被破坏，并重新发送。
                    由于确认分组较小，TCP规定允许发送相同方向的分组对其进行捎带。有效利用网络资源，为了增加确认报文找到同向报文的可能性，
                    TCP 实现了一种‘延时确认’算法。
                    延时确认算法: 就是在规定时间内找相同传输方向的数据分组，如果没找到则单独一个分组。
                    又因服务器不会主动发出请求，所以导致延时算法会引入延时。
                5) TIME_WAIT时延和端口耗尽:
                    TIME_WAIT状态主要就是为了解决这个问题：防止延迟的无效消息包被误认为是合法的。
                    TIME_WAIT状态持续时间是两倍的MSL，MSL是TCP包的最大存活时间，一个TCP包一旦在网络上存活超过MSL，会直接被丢弃。
                    TCP包的最大存活时间，一个TCP包一旦在网络上存活超过MSL，会直接被丢弃。
                    当某个TCP 连接关闭时， 会在内存中维护一个数据块。用来记录最近关闭连接的IP地址和端口号。这类信息只会存在一小段时间。(
                    最大分段使用期,约两分钟)，确保在这段时间内不会出现相同的连接和端口号。
            3. HTTP 连接优化:

                1. 并行连接:
                    由以前的串行HTTP事务，改成并行的HTTP事务会一定程度上提高加载速度。
                    问题:
                        1.当网络带宽有限制的时候，并行的HTTP事务就会同时去竞争带宽资源，这样带来的性能提升就很小。而且同时打开大量的
                        连接对服务器的性能会用严重的影响。
                        2.浏览器确实使用了并行连接，但是会限制并行数。
                        3.每条连接的建立会耗费时间和带宽。
                        4.由于TCP慢启动特性的存在，导致每条连接的传输性能不高。
                    结论: 虽然并行连接带来的性能提升有限，但是用户看到页面上所有组件都在加载，会感觉性能得到提升了。
                2. 持久连接:
                    优点: 持久连接降低了时延和建立连接的开销，并将连接保持在了调谐状态，减少了打开连接的数量。
                    缺点: 会出现大量空闲连接，耗费本地，远程客户端和服务器的资源。
                    HTTP1.0 keep-alive 连接:
                        keep-alive 只是将连接保持在活跃状态。发出keep-alive请求后，客户端和服务器不一定同意建立持久连接。
                        它们可以随时关闭空闲的持久连接，并限制持久连接可处理HTTP事务的数量。
                        可用 Keep-Alive 首部来指定参数信息，而且只用在指定了 Connection: keep-alive时，Keep-Alive首部才起
                        作用。
                    keep-alive 连接与限制:
                        1. keep-alive 必须随请求报文一起发送出去，才可能建立持久连接。
                        2. 如果响应首部中没有 keep-alive, 就知道服务器不允许建立 持久连接。
                        3. 只有在无需检测连接是否关闭就能知道实体长度的情况下才能保持持久连接，也就是说在实体首部中必须包含connect-length,
                        如果传输错误的connect-length, 服务端就不能检测出一条报文的结束和另一条报文的开始了。
                        4. 代理和网关必须执行 connection首部规则。代理或网关再将报文转发出去前必须删掉connection首部及 在connection首部
                        命名中的所有首部。
                    keep-alive 和哑代理:
                        1. 客户端的 Connection: Keep-Alive 只对这条离开客户端的链路产生影响。
                        2. 哑代理: 它只会逐字节的转发客户端的请求报文，而部队connection及相关首部做任何处理，当服务器收到请求报文时如果同意
                        建立持久连接就会和代理建立一条持久连接，而哑代理对这一些没有丝毫感知，就将响应报文反给客户端, 然后等待服务端断开连接。
                        客户端收到响应后解析到有connection:keep-alive就和代理建立已持久连接。此时服务端和客户端以为它们之间已经建立起持久
                        连接，而哑代理却对keep-alive一无所知。客户端收到请求后会立即发送下一条报文，而代理却认为同一条连接不会有请求过来，所以
                        拒绝请求，导致浏览器在这里转圈。
                        3. 不能被转发的首部: Proxy-Connection, Proxy-Authenticate, Upgrade, Transfer-Encoding
                    Http1.1 keep-alive:
                        默认时激活的，除非在响应报文中显示收到 connection:close.
                        1. 一个客户端最多同时维持两条持久连接,防止服务器过载.
                        2. http1.1 的代理能分别管理客户端和服务器的持久连接,每个持久连接只适用于下一跳的传输.
                3. 管道化连接:
                    定义: 可以同时发送多条请求, 在高延时的网络环境下, 可以降低网络的环回时间,提高性能.
                    缺点:
                        1. 响应报文必须按照请求的顺序返回,因为请求报文没有序列标签,如果响应顺序错乱,就没办法与请求对应了.
                        2. 客户端不应该用管道化的方式发送会产生副作用的请求(例: post). 出错的时候,管道化的方式会阻碍客户端了解哪些请求
                        没有被执行.
                        3. 不能发送非幂等事务, GET, PUT, HEAD, DELETE, 都是幂等事务.
                    幂等事务: 反复被执行多次返回结果相同的事务.

                4. 正常关闭连接

    4. web服务器:

    5. 代理:
        私有代理: 单个客户端专用
        公共代理: 众多客户端共享.
            使用场景:
                高速缓存代理服务器, 会利用客户端相同的请求.
        代理与网关的区别:
            代理连接两个或多个使用相同协议的程序.
            网关担任协议转换的角色, 连接两个或多个使用不同的协议程序.
        代理请求中棘手的问题:
            1. 代理请求中的URI与服务器请求URI有何不同:
                一旦客户端配置了代理就会发送完整的URI, 因为代理服务器需要根据完整的URI知道目的服务器的名称.
                而没有配置代理只需要发送资源路经.
            2. 拦截 和 反向代理是如何将服务器主机信息隐藏起来的:

            3. 修改URI规则:

            4. 代理是怎么影响浏览器的智能URI自动完成机制:

    6. 缓存:
        缓存带来的优势:
        1. 降低冗余的数据传输:
            当客户端请求静态资源时, 为了避免这些静态资源一遍遍在网络中传输, 耗尽宽带资源, 可以将这些资源放在
            缓存中. 后续请求又缓存响应.
        2. 缓解宽带瓶颈:
            很多网络为本地网络提供的宽带远大与远程服务器的宽带. 客户端会以路径上最慢的网速访问服务器.
            如果在本地局域网又缓存, 将会大大提高性能.
        3. 瞬间拥塞:
            缓存对缓解瞬间拥塞有极大的作用. 当大量请求瞬间访问服务器时, 就会造成瞬间拥塞. 这会给服务器和web服务带来灾难性的影响.
        4. 距离时延:

        5. 对缓存内容验证:
            缓存服务器不定时的对缓存副本的有效性进行验证. 为了避免网络带宽的浪费, 大多数缓存都会在客户端发出请求, 并且副本旧的需要
            验证了, 才会向源服务器发送验证请求, 如果副本没有修改 会返回304.
        6. 判断缓存是否命中:
            Date: 客户端可以根据响应的Date字段来判断, 如果Date首部的值比当前时间早, 可以认为命中缓存.
            Age: 当代理服务器用自己缓存的实体去响应请求时，用该头部表明该实体从产生到现在经过多长时间了
        7. 缓存副本的新鲜度检测:

        8. 缓存和广告:
            发布广告者的困境:
            缓存可以降低内容运营商的网络费用, 并且可以将文章和广告以最高的效率发送给用户. 鼓励用户去访问更多的广告和文章.
            但是内容运营商是靠向用户推送消息的数量来盈利的, 而缓存的存在会想源服务器隐藏了用户的实际访问次数. 如果靠访问次数盈利就完了.
            手段:
            1. 使用缓存清除技术.

            2. 日志迁移.
                缓存自己将命中记录下来,  并定时的向原服务器发送记录日志. 但是日志规模大, 很难移动, 而且还有安全隐私问题.
            3. 命中次数和使用限制.
                HTTP 提供了一个Meter首部, 该首部记录特定URL的访问次数,并定时的向服务器返回.
                服务器还可以为缓存设置过时时钟.
    7. 集成点: 网关, 隧道及中继
        简介:  使用http 与其他应用协议或者应用程序进行通信.
        网关:

        隧道:

        中继:

    8. 客户端识别与cookie机制:

        识别客户端机制:
            1. HTTP 首部:
                Form:  用户emial地址.
                User-Agent:  用户浏览器信息.
                Referer:  记录用户是从哪个URL地址跳转过来的.
                Authorization:  用户账号密码.
                Client-IP:  客户端IP地址.

                Cookie: 服务器产生的ID标签.
            2. 客户端IP地址:
                1. 为提高安全性, 并对IP地址进行管理, 客户端都是通过网络地址转换(NAT) 防火墙来浏览网络内容的, 防火墙会隐藏客户端真实的IP地址,
                转换成一个共享的防火墙IP地址(和不同的端口号)
                2. 有些请求会通过HTTP代理或网关转发到源服务器, 为了使服务器看到真是的IP地址, 在转发是会添加特殊首部Client-IP或者
                X-Forwarded-For来保存真实IP.
            3. 用户登录:
                1.首先浏览器会返回401 并返回一个WWW-Authorization首部, 要求用户进行登录.
                2.当用户在输入用户密码后, 浏览器会自动加上Authorization首部, 并对用户密码进行加蜜.
            4. 胖URL:

            5. cookie:
                cookie分为:
                    持久cookie:
                    会话cookie: 会话cookie在用户退出浏览器的时候回自动删除.


    9. 基本认证:

    10. 摘要认证:
        摘要认证基于基本认证的改进:
            1. 不会明文传输账号密码: 通过计算账号的摘要, 向服务器发送摘要不用发送账号信息.计算摘要函数(md5, sha1等)
            2. 防止恶意用户捕获并重放认证握手过程.
            3. 有选择的防止报文被篡改.
            4.
        用随机数防止重放攻击:
            服务端生成一个随机数, 并发给客户端, 该随机数不断变化. 客户端计算摘要的时候加上随机数一起计算.
            缺点: 随机数是在www-authenticate 质询中发送给客户端的, 这很容易被截获.
    11. HTTPS:
        数字加密:
            1. 密码: 对文本进行编码, 使偷窥者无法识别.
            2. 密钥: 改变密码行为的数字化参数.
            3. 对称加密: 加/解密使用相同的算法密钥
            4. 非对称加密:
            5. 数字签名: 用来校验报文是否被伪造和篡改的校验和.
            6. 数字证书: 又一个可信组织验证和签发的识别信息.
            7. 公开加密:

    12. 实体和首部:
        基本字体首部:
            1. Content-Type: 实体中承载的对象类型
            2. Content-Length: 传送实体的长度
            3. Content-Language: 与传送对象最想配的语言
            4. Content-Encoding: 对象所作的编码转换
            5. Content-Location: 请求时可通过它获得对象
            6. Content-Range: 部分实体
            7. Content-MD5: 实体主体内容的校验和
            8. Last-Modified: 创建和最后修改日期
            9. Expires: 失效日期
            10. Allow: 允许的请求方法
            11. ETag: 实体的唯一验证码
            12. Cache-Control: 控制如何缓存文档
            13. Transfer-Encoding: 指明字节流是分块传输的.
            客户端是如何让服务器知道数据是分块传输的: 状态码 100, 客户端再请求中添加首部: Expect: 100-continue.
            如果服务器接受请求, 会发送 HTTP/1.1 continue 100.

        内容编码类型:
            1. gzip: 采用 gzip编码
            2. compress: 采用unix 文件压缩程序
            3. deflate: 采用zlib压缩
            4. identity: 没有压缩
        传输编码和分块编码:


